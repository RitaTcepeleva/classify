{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные содержатся в файле `data/lin_reg.txt`. Прочитать их можно следующим так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "D = np.loadtxt('../data/lin_reg.txt', delimiter=',')\n",
    "X = D[:, :-1]\n",
    "Y = D[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При выполнении заданий **нельзя** пользоваться `scikit-learn` и т.п., только `NumPy`/`JAX`/`TF`/`PyTorch` и `matplotlib`/`seaborn`/`plotly`/etc.\n",
    "\n",
    "1. Нарисуйте график среднеквадратичной ошибки в зависимости от параметра регуляризации $\\alpha$, используя полные данные для обучения и для тестирования. \n",
    "2. Подготовьте исходные данные для 5 fold CV.\n",
    "3. С помощью CV найдите оптимальное значение $\\alpha$ на какой-нибудь сетке значений.\n",
    "4. Постройте валидационную кривую. \n",
    "5. Постройте кривую обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Читаем data/lin_reg.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8abc2ecd6335>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/lin_reg.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "D = np.loadtxt('data/lin_reg.txt', delimiter=',')\n",
    "X = D[:, :-1]\n",
    "y = D[:, -1]\n",
    "\n",
    "X = torch.tensor(X, dtype=torch.float)\n",
    "y = torch.tensor(y, dtype=torch.float)\n",
    "\n",
    "X = torch.hstack((torch.ones(X.shape[0], 1), X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейная регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    return (y_true - y_pred).pow(2).mean()\n",
    "\n",
    "\n",
    "class LinearRegression:\n",
    "    def __init__(self, lr=0.001, momentum=0.9, loss=mse, regulization=\"L2\", C=0.1, epochs=100, batch_size=100):\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.loss = loss\n",
    "        self.reguliztion = regulization\n",
    "        self.C = C\n",
    "        self.batch_size=batch_size\n",
    "        \n",
    "        self.theta = None\n",
    "        self.losses = None\n",
    "        self.prev_grad = 0\n",
    "        self.epochs = 100\n",
    "        \n",
    "    def fit(self, X, y, disable_bar=False):\n",
    "        self.theta = torch.rand(X.shape[1], requires_grad=True)\n",
    "        \n",
    "        epoch = 0\n",
    "        self.losses = []\n",
    "        n_iters = X.shape[0] // self.batch_size\n",
    "        \n",
    "        for epoch in tqdm(range(self.epochs), disable=disable_bar):\n",
    "            loss_acc = 0\n",
    "            for i in range(n_iters):\n",
    "                y_pred = X[i * self.batch_size: (i + 1) * self.batch_size] @ self.theta\n",
    "                loss = self.loss(y[i * self.batch_size: (i + 1) * self.batch_size], y_pred)\n",
    "\n",
    "                if self.reguliztion == \"L2\":\n",
    "                    loss += self.C * torch.norm(self.theta)\n",
    "\n",
    "                loss.backward()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    loss_acc += loss.item()\n",
    "\n",
    "                    grad = self.lr * self.theta.grad\n",
    "                    if self.momentum:\n",
    "                        grad += self.momentum * self.prev_grad\n",
    "\n",
    "                    self.theta -= grad\n",
    "                    self.prev_grad = grad\n",
    "\n",
    "                    self.theta.grad.zero_()\n",
    "                        \n",
    "            self.losses.append(loss_acc / n_iters)\n",
    "\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return X @ self.theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-1cd9b652eb51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "reg = LinearRegression(lr=0.0005, C=1, momentum=0.9, batch_size=100)\n",
    "\n",
    "reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict(X)\n",
    "mse(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def plot_losses(reg, color=\"r\", label=\"Learning losses\"):\n",
    "    plt.plot(reg.losses, color, label=label)\n",
    "\n",
    "plt.figure(figsize=(16, 9))\n",
    "plot_losses(reg)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_C(losses, Cs, color=\"r\", label=\"val mse\"):\n",
    "    plt.plot(cs, losses, color=color, label=label)\n",
    "    plt.xlabel(\"C\")\n",
    "    plt.ylabel(\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_losses = []\n",
    "train_losses = []\n",
    "cs = np.arange(0.01, 10, 0.3)\n",
    "\n",
    "for C in cs:\n",
    "    reg = LinearRegression(C=C)\n",
    "\n",
    "    reg.fit(X, y, disable_bar=True)\n",
    "    \n",
    "    y_pred = reg.predict(X)\n",
    "    c_losses.append(mse(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 9))\n",
    "plot_C(c_losses, cs, label=\"MSE on all data\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossVal:\n",
    "    def __init__(self, n_items, n_splits=5):\n",
    "        self.n_items = n_items\n",
    "        self.n_splits = n_splits\n",
    "    \n",
    "    def splits(self):\n",
    "        indicies = np.arange(self.n_items)\n",
    "        split_size = self.n_items // self.n_splits\n",
    "        \n",
    "        for i in range(self.n_splits):\n",
    "            train_indicies = indicies[0: i * split_size]\n",
    "            train_indicies = np.hstack((train_indicies, indicies[(i+1) * split_size:]))\n",
    "            \n",
    "            val_indicies = indicies[i * split_size: (i + 1) * split_size]\n",
    "            yield (train_indicies, val_indicies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_score(Regressor, X, y, n_splits=5, **params):\n",
    "    reg = Regressor(**params)\n",
    "    \n",
    "    scores = np.zeros(n_splits)\n",
    "    train_scores = np.zeros(n_splits)\n",
    "    cv = CrossVal(X.shape[0])\n",
    "\n",
    "    for i, (train_indicies, val_indicies) in enumerate(cv.splits()):\n",
    "        reg.fit(X[train_indicies], y[train_indicies], disable_bar=True)\n",
    "        y_pred = reg.predict(X[val_indicies])\n",
    "        scores[i] = mse(y[val_indicies], y_pred)\n",
    "        y_pred = reg.predict(X[train_indicies])\n",
    "        train_scores[i] = mse(y[train_indicies], y_pred)\n",
    "        \n",
    "    return scores, train_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(LinearRegression, X, y, C=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_losses = []\n",
    "train_losses = []\n",
    "cs = np.arange(0.01, 10, 0.3)\n",
    "\n",
    "for C in cs:\n",
    "    scores, train_scores = cross_val_score(LinearRegression, X, y, C=C, momentum=0.8)\n",
    "    c_losses.append(scores.mean())\n",
    "    train_losses.append(train_scores.mean())\n",
    "    \n",
    "plt.figure(figsize=(16, 9))\n",
    "plot_C(c_losses, cs, label=\"mse on val\")\n",
    "plot_C(train_losses, cs, color=\"b\", label=\"mse on train\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random search cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class RandomSearchCV:\n",
    "    def __init__(self, n_trials, params_bound, n_splits=5):\n",
    "        self.n_trials = n_trials\n",
    "        self.params_bound = params_bound\n",
    "        self.n_splits = n_splits\n",
    "        \n",
    "    def search(self, Regressor, X, y):\n",
    "        scores = []\n",
    "        for i in tqdm(range(self.n_trials)):\n",
    "            params = {\n",
    "                key: random.uniform(v[0], v[1])\n",
    "                for key, v in self.params_bound.items()\n",
    "            }\n",
    "            scores.append({\n",
    "                \"params\": params,\n",
    "                \"scores\": cross_val_score(Regressor, X, y, n_splits=self.n_splits, **params)[0].mean()\n",
    "            })\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = RandomSearchCV(100, {\n",
    "    \"lr\": (0.001, 0.00001),\n",
    "    \"C\": (0.1, 10),\n",
    "    \"momentum\": (0.5, 0.95)\n",
    "})\n",
    "\n",
    "results = search.search(LinearRegression, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(results, key=lambda x: x[\"scores\"])[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
